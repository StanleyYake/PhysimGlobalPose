#! /usr/bin/env python
import sys, os
import numpy as np
import rospy
import matplotlib.pyplot as plt
from pylab import *
import cv2
from PIL import Image
from keras.preprocessing.image import *
from keras.models import load_model
import keras.backend as K
from keras.applications.imagenet_utils import preprocess_input

import tensorflow as tf2
import time

# Verify if path is set in bashrc
if os.environ.get('PHYSIM_GLOBAL_POSE') == None:
    print("Please set PHYSIM_GLOBAL_POSE in bashrc!")
    sys.exit()

g_repo_path = os.environ['PHYSIM_GLOBAL_POSE']

sys.path.append(g_repo_path + "/src/3rdparty")

from models import *
from fcn_segmentation_package.srv import *

active_object_list = []
active_frame = ''

apc_objects = {0: 'background', 1: 'crayola_24_ct', 2: 'expo_dry_erase_board_eraser', 3: 'folgers_classic_roast_coffee',
            4: 'scotch_duct_tape', 5: 'up_glucose_bottle', 6: 'laugh_out_loud_joke_book', 7: 'soft_white_lightbulb',
            8: 'kleenex_tissue_box', 9: 'dove_beauty_bar', 10: 'elmers_washable_no_run_school_glue', 11: 'rawlings_baseball'}

ycb_objects = {0: 'background', 1: '002_master_chef_can', 2: '003_cracker_box', 3: '004_sugar_box',
            4: '005_tomato_soup_can', 5: '006_mustard_bottle', 6: '007_tuna_fish_can', 7: '008_pudding_box',
            8: '009_gelatin_box', 9: '010_potted_meat_can', 10: '011_banana', 11: '019_pitcher_base',
            12: '021_bleach_cleanser', 13: '024_bowl', 14: '025_mug', 15: '035_power_drill',
            16: '036_wood_block', 17: '037_scissors', 18: '040_large_marker', 19: '051_large_clamp',
            20: '052_extra_large_clamp', 21: '061_foam_brick'}

# model = []
class segmentation:
  def __init__(self, checkpoint_path, model_name, image_size, num_classes):
    # global model
    config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))
    self.session = tf.Session(config=config)
    K.set_session(self.session)

    self.image_size = image_size
    self.num_classes = num_classes
    self.batch_shape = (1, ) + self.image_size + (3, )
    self.checkpoint_path = checkpoint_path
    print (model_name)
    self.model = globals()[model_name](batch_shape=self.batch_shape, input_shape=(640, 640, 3), classes=self.num_classes)

    print (checkpoint_path)
    self.model.load_weights(checkpoint_path, by_name=True)
    self.model.summary()

    self.graph = tf2.get_default_graph()

  def handle_get_segments(self, req):
    global active_object_list
    global active_frame
    global object_map

    print(active_object_list)
    print(active_frame)
    print(req.scene_path + 'frame-000000.color.png')

    results = []

    image = Image.open('%s' % (req.scene_path + 'frame-000000.color.png'))
    image_np = img_to_array(image)
    image_np = image_np[...,:3]
    img_h, img_w = image_np.shape[0:2]

    pad_w = max(self.image_size[1] - img_w, 0)
    pad_h = max(self.image_size[0] - img_h, 0)
    image_np = np.lib.pad(image_np, ((pad_h/2, pad_h - pad_h/2), (pad_w/2, pad_w - pad_w/2), (0, 0)), 'constant', constant_values=0.)

    image_np = np.expand_dims(image_np, axis=0)
    image_np = preprocess_input(image_np)

    print (image_np.shape)
    with self.graph.as_default():
        start = time.time()
        result = self.model.predict(image_np, batch_size=1)
        end = time.time()
        print(end - start)

    start = time.time()
    prob_result = result[0]

    # get per-pixel class wise probability
    # prob_result = np.exp(prob_result)
    # prob_sum = np.sum(prob_result, axis=2)
    # prob_sum = np.tile(prob_sum, (self.num_classes,1,1))
    # prob_sum = np.swapaxes(prob_sum, 0, 1)
    # prob_sum = np.swapaxes(prob_sum, 1, 2)
    # prob_result = np.divide(prob_result, prob_sum)

    # get per class probability

    active_object_list = active_object_list + (0,)
    for classVal in active_object_list:
        class_prob = prob_result[:,:,classVal]
        super_threshold_indices = class_prob < 0
        class_prob[super_threshold_indices] = 0
        class_max = np.ndarray.max(class_prob)
        class_prob = class_prob/class_max
        class_prob = class_prob*10000
        class_prob_int = class_prob.astype(np.uint16)
        class_prob_int = class_prob_int[pad_h/2:pad_h/2+img_h, pad_w/2:pad_w/2+img_w]
        cv2.imwrite(os.path.join(req.scene_path,'debug_super4PCS/%s.png' % (object_map[classVal])), class_prob_int)

    # result = np.argmax(np.squeeze(result), axis=-1).astype(np.uint16)
    # result_img = result[pad_h/2:pad_h/2+img_h, pad_w/2:pad_w/2+img_w]
    # result_img = result_img.astype(np.uint16)
    # cv2.imwrite(os.path.join(req.scene_path,'debug_super4PCS/frame-000000.fcn.mask.png'), result_img)

    # result_img_class = result_img.astype(np.uint8)
    # result_img_class = Image.fromarray(result_img_class, mode='P')
    # result_img_class.putpalette([
    # 0, 0, 0, # black background
    # 255, 0, 0, # index 1
    # 255, 128, 0, # index 2
    # 255, 255, 0, # index 3
    # 128, 255, 0, # index 4
    # 0, 255, 0, # index 5
    # 0, 255, 128, # index 6
    # 0, 255, 255, # index 7
    # 0, 128, 255, # index 8
    # 0, 0, 255, # index 9
    # 127, 0, 255, # index 10
    # 255, 0, 255, # index 11
    # 255, 0, 127, # index 12
    # 128, 128, 128, # index 13
    # 255, 204, 204, # index 14
    # 204, 204, 255, # index 15
    # 204, 255, 255, # index 16
    # 204, 102, 0, # index 17
    # 153, 153, 0, # index 18
    # 102, 0, 51, # index 19
    # 102, 102, 0, # index 20
    # 255, 255, 255, # index 21
    # ])

    # result_img_class.save(os.path.join(req.scene_path,'debug_super4PCS/frame-000000.fcn.class.png'))
    end = time.time()
    print(end - start)
    return 1
    

def update_active_object_list_and_frame(req):
    global active_object_list
    global active_frame
    active_object_list = req.active_list
    active_frame = req.active_frame
    return 1

if __name__ == '__main__':
    global object_map

    model_name = 'FCN_Vgg16_32s'
    image_size = (640, 640)

    # weight_file = 'ycb_weights_synthetic.hdf5'
    weight_file = 'ycb_weights.hdf5'
    # weight_file = 'apc_weights.hdf5'

    num_classes = 22
    # num_classes = 12

    object_map = ycb_objects
    # object_map = apc_objects

    checkpoint_path = os.path.join(g_repo_path, 'src/3rdparty/fcn_segmentation_package/Models/FCN_Vgg16_32s', weight_file)

    seg = segmentation(checkpoint_path, model_name, image_size, num_classes)
    print '\n\nLoaded network'

    ## Listen to the image topic and detect objects
    rospy.init_node('detector', anonymous=True)
    
    s1 = rospy.Service('handle_get_segments', UpdateSeg, seg.handle_get_segments)
    s2 = rospy.Service('update_active_list_and_frame', UpdateActiveListFrame, update_active_object_list_and_frame)
    rospy.spin()